{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8951d5f5",
   "metadata": {
    "id": "8951d5f5"
   },
   "source": [
    "# IEOR 242A HW4 Starter Code â€” Fall 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80e3964a",
   "metadata": {
    "code_folding": [],
    "id": "80e3964a"
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "# TODO: Put all dependencies here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1267ae20",
   "metadata": {
    "code_folding": [],
    "id": "1267ae20"
   },
   "outputs": [],
   "source": [
    "# Load in data\n",
    "rawtrain=pd.read_csv('Letters_train_2024.csv')\n",
    "rawtest=pd.read_csv('Letters_test_2024.csv')\n",
    "# TODO: Load in data (after analyzing the dataset, delete any ouputs such as df.inf(), df.head(), et).\n",
    "# this cell should not output anything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6a9df",
   "metadata": {
    "id": "86d6a9df"
   },
   "source": [
    "# Question 1 (50 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73e377b6",
   "metadata": {
    "code_folding": [],
    "id": "73e377b6"
   },
   "outputs": [],
   "source": [
    "# TODO: Create new variable here\n",
    "rawtrain['isB']=(rawtrain['letter']=='B').astype(bool)\n",
    "rawtest['isB']=(rawtest['letter']=='B').astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "039a5cd0",
   "metadata": {
    "code_folding": [],
    "id": "039a5cd0"
   },
   "outputs": [],
   "source": [
    "# TODO: Split into X and y\n",
    "X_train=rawtrain.drop(columns=['letter','isB'])\n",
    "y_train=rawtrain['isB']\n",
    "X_test=rawtest.drop(columns=['letter','isB'])\n",
    "y_test=rawtest['isB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2e726",
   "metadata": {
    "id": "a7c2e726"
   },
   "source": [
    "### Part A: Baseline Model (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5a6931e",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "a5a6931e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.7540\n"
     ]
    }
   ],
   "source": [
    "# Q1A code\n",
    "\n",
    "#TODO: find the most common label\n",
    "def baselineBModel(x):\n",
    "    return False\n",
    "# TODO: calcuate baseline accuracy\n",
    "baseline_1_acc = (y_test == X_test.apply(baselineBModel, axis=1)).mean()\n",
    "print(f'Baseline Test Accuracy: {baseline_1_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f7dca",
   "metadata": {
    "id": "eb0f7dca"
   },
   "source": [
    "### Part B: Logistic Regression (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fba5965",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "7fba5965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9369\n"
     ]
    }
   ],
   "source": [
    "# Q1B code\n",
    "\n",
    "# TODO: For all questions: Create and train model, then make predictions, then calculate accuracy\n",
    "# TODO: calcuate logistic accuracy accuracy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_1b = LogisticRegression(max_iter=10000) #unnormalized data causes convergence issues\n",
    "model_1b.fit(X_train, y_train)\n",
    "model_1b_acc = model_1b.score(X_test, y_test)\n",
    "print(f'Logistic Regression Test Accuracy: {model_1b_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495157d",
   "metadata": {
    "id": "7495157d"
   },
   "source": [
    "### Part C: AUC (4 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94594df9",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "94594df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test AUC: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# Q1C code\n",
    "# TODO: Calculate logistic AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "model_1b_auc = roc_auc_score(y_test, model_1b.predict_proba(X_test)[:,1])\n",
    "print(f'Logistic Regression Test AUC: {model_1b_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75df07",
   "metadata": {
    "id": "ba75df07"
   },
   "source": [
    "### Part D: Cross-validated CART (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6132e51",
   "metadata": {
    "id": "a6132e51"
   },
   "source": [
    "**Written Answer**: As the dataset is relatively small, I simply iterated through all the values from 0 to 0.1 with an interval of 1/10000 for ccp alpha value (empirically, the optimal value should not exceed 0.1). The value with the highest cross validtaion (cv=5) accuracy is selected by GridSearchCV. (It can be optimized for efficiency using cost_complexity_pruning_path to find 'valid/useful' ccp alpha values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dee59e95",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "dee59e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV CART Test Accuracy: 0.9422\n",
      "Best ccp_alpha: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# Q1D Code\n",
    "# TODO: calculate best CV accuracy\n",
    "# TODO: get best ccp_alpha\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_1d = DecisionTreeClassifier()\n",
    "param_grid = {'ccp_alpha': np.linspace(0, 0.1, 1000)} #should be a good range\n",
    "grid = GridSearchCV(model_1d, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "model_1d_best_ccp_alpha = grid.best_params_['ccp_alpha']\n",
    "model_1d_acc = grid.score(X_test, y_test)\n",
    "print(f'CV CART Test Accuracy: {model_1d_acc:.4f}')\n",
    "print(f'Best ccp_alpha: {model_1d_best_ccp_alpha:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65edd8a",
   "metadata": {
    "id": "f65edd8a"
   },
   "source": [
    "### Part E: Random Forest (10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28f7acb2",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "28f7acb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "# Q1E Code\n",
    "# TODO: calculate random forest accuracy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_1e = RandomForestClassifier(random_state = 2024) # I'll consider RF as improved bagging and need this random state\n",
    "model_1e.fit(X_train, y_train)\n",
    "model_1e_acc = model_1e.score(X_test, y_test)\n",
    "print(f'Random Forest Test Accuracy: {model_1e_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53648a60",
   "metadata": {
    "id": "53648a60"
   },
   "source": [
    "### Part F: Performance Comparison (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bfd25",
   "metadata": {
    "id": "e74bfd25"
   },
   "source": [
    "**Written Answer**: Random Forest did the best. In this case, I would argue that accuracy is more important as interpretability of what makes a \"B\" a \"B\" is arguably relatively useless to human beings unless it's under certain special circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0015fa9c",
   "metadata": {
    "code_folding": [],
    "id": "0015fa9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "0             Baseline  0.754011\n",
      "1  Logistic Regression  0.936898\n",
      "2                 CART  0.942246\n",
      "3        Random Forest  0.971123\n"
     ]
    }
   ],
   "source": [
    "# Q1F Code\n",
    "# TODO: create df to compare performance\n",
    "model_df = pd.DataFrame({'Model': ['Baseline', 'Logistic Regression', 'CART', 'Random Forest'],\n",
    "                         'Accuracy': [baseline_1_acc, model_1b_acc, model_1d_acc, model_1e_acc]})\n",
    "print(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4307762",
   "metadata": {
    "id": "e4307762"
   },
   "source": [
    "***\n",
    "# Question 3 (50 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0dd917ee",
   "metadata": {
    "code_folding": [],
    "id": "0dd917ee"
   },
   "outputs": [],
   "source": [
    "# TODO: Redefine target y\n",
    "y_train = rawtrain['letter']\n",
    "y_test = rawtest['letter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2553f29",
   "metadata": {
    "id": "e2553f29"
   },
   "source": [
    "### Part A: Baseline Model (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d84b11f",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "3d84b11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.2610\n"
     ]
    }
   ],
   "source": [
    "# Q2A\n",
    "# TODO: calculate baseline accuracy\n",
    "letterModel = y_train.mode()[0]\n",
    "#print(letterModel) #it's P\n",
    "baseline_2_acc = (y_test == letterModel).mean()\n",
    "print(f'Baseline Test Accuracy: {baseline_2_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f682d",
   "metadata": {
    "id": "555f682d"
   },
   "source": [
    "### Part B: LDA (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8860299d",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "8860299d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test Accuracy: 0.9187\n"
     ]
    }
   ],
   "source": [
    "# Q2B code\n",
    "# Calculate LDA accuracy\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model_2b = LinearDiscriminantAnalysis()\n",
    "model_2b.fit(X_train, y_train)\n",
    "model_2b_acc = model_2b.score(X_test, y_test)\n",
    "print(f'LDA Test Accuracy: {model_2b_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75cc6e",
   "metadata": {
    "id": "3c75cc6e"
   },
   "source": [
    "### Part C: Cross-validated CART (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80208cc3",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "80208cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Test Accuracy: 0.9123\n"
     ]
    }
   ],
   "source": [
    "# Q2C Code\n",
    "# TODO: calculate CV CART accuracy\n",
    "model_2c = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(model_2c, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "model_2c_best_ccp_alpha = grid.best_params_['ccp_alpha']\n",
    "model_2c_acc = grid.score(X_test, y_test)\n",
    "print(f'CART Test Accuracy: {model_2c_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31acb6",
   "metadata": {
    "id": "1a31acb6"
   },
   "source": [
    "### Part D: Vanilla Bagging (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce7d3724",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "ce7d3724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CV Random Forest Test Accuracy: 0.9401\n"
     ]
    }
   ],
   "source": [
    "# Q2D\n",
    "# TODO: Calculate vanilla bagging accuracy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_2d = RandomForestClassifier(max_features=len(X_train.columns),random_state = 2024)\n",
    "model_2d.fit(X_train, y_train)\n",
    "model_2d_acc = model_2d.score(X_test, y_test)\n",
    "print(f'No CV Random Forest Test Accuracy: {model_2d_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d3365",
   "metadata": {
    "id": "903d3365"
   },
   "source": [
    "### Part E: Cross-validated Random Forest (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd352e1",
   "metadata": {},
   "source": [
    "Written answer: Same as problem 1, because the dataset is relatively small, I simply iterated through all the values from 1 to n_features for max_feature. The value with the highest cross validtaion (cv=5) accuracy is selected by GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2bae54c",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "f2bae54c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_features: 4\n",
      "CV Random Forest Test Accuracy: 0.9658\n"
     ]
    }
   ],
   "source": [
    "# Q2E\n",
    "# TODO: Calculate RF accuracy, use cross-validation to select the max_features\n",
    "model_2e = RandomForestClassifier(random_state = 2024)\n",
    "param_grid = {'max_features': np.arange(1, len(X_train.columns)+1)}\n",
    "grid = GridSearchCV(model_2e, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "model_2e_best_max_features = grid.best_params_['max_features']\n",
    "model_2e_acc = grid.score(X_test, y_test)\n",
    "print(f'Best max_features: {model_2e_best_max_features}')\n",
    "print(f'CV Random Forest Test Accuracy: {model_2e_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969e7f2",
   "metadata": {
    "id": "1969e7f2"
   },
   "source": [
    "### Part F: Gradient Boosting Classifier (9 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9bd4e72",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "f9bd4e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC Test Accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "# Q2F\n",
    "# Calculate boosting accuracy\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_2f = GradientBoostingClassifier(n_estimators = 300, max_leaf_nodes = 15, random_state = 2024)\n",
    "model_2f.fit(X_train, y_train)\n",
    "model_2f_acc = model_2f.score(X_test, y_test)\n",
    "print(f'GBC Test Accuracy: {model_2f_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
